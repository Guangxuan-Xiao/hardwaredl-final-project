{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brazilian-judge",
   "metadata": {},
   "source": [
    "# Your name: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-consciousness",
   "metadata": {},
   "source": [
    "This notebook implements timeloop/accelergy-based energy estimation for the neural network model you trained. This part has to be run with the docker we provide, and does not require GPU support. \n",
    "\n",
    "One strategy to reduce the profiling time is to design a model with repeated layers since layers with the same architecture only need one time of profiling.\n",
    "The profiler will also automatically save the information of profiled layers to a .json file specifiled by `profiled_lib_dir`, so that next time the same layer is profiled, the results can be obtained immediately. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-thought",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c09bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your own model [TODO]\n",
    "# HINT : You might want to consider a network using depth-wise convolution and residual connection!\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(oup, oup, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(inp, oup, 1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv(x)\n",
    "        x += self.downsample(residual)\n",
    "        x = F.relu6(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # build a network with InvertedResidual\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(3, 16, 3, 1, 1, bias=False))\n",
    "        layers.append(nn.BatchNorm2d(16))\n",
    "        layers.append(nn.ReLU6(inplace=True))\n",
    "        layers.append(InvertedResidual(16, 32, 2))\n",
    "        layers.append(InvertedResidual(32, 64, 2))\n",
    "        layers.append(InvertedResidual(64, 64, 2))\n",
    "        layers.append(InvertedResidual(64, 128, 2))\n",
    "        layers.append(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        layers.append(nn.Flatten())\n",
    "        layers.append(nn.Linear(128, 10))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7779111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-hollow",
   "metadata": {},
   "source": [
    "## Run the Profiler to estimate the peak activation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "former-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Activation Sizes: 98304.0 Byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "from profiler import count_activation_size\n",
    "peak_activation_size = count_activation_size(\n",
    "    net=model,\n",
    "    input_size=(1, 3, 32, 32),\n",
    ")\n",
    "\n",
    "print(\"Peak Activation Sizes: {} Byte\".format(peak_activation_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-advertising",
   "metadata": {},
   "source": [
    "## Run the Profiler for Timeloop/Accelergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "needed-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting nn.Conv2d and nn.Linear in network-Feb-28-2023 model ...\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.activation.ReLU6'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.activation.ReLU6'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class '__main__.InvertedResidual'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.activation.ReLU6'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class '__main__.InvertedResidual'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.activation.ReLU6'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class '__main__.InvertedResidual'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.activation.ReLU6'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "unknown module type <class '__main__.InvertedResidual'>\n",
      "unknown module type <class 'torch.nn.modules.flatten.Flatten'>\n",
      "unknown module type <class '__main__.Net'>\n",
      "conversion complete!\n",
      "\n",
      "running timeloop to get energy and latency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:32<00:00, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeloop running finished!\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer1 \t Energy: 40.26 \t Cycle: 9216 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer2 \t Energy: 31.90 \t Cycle: 4608 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer3 \t Energy: 61.11 \t Cycle: 9216 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer4 \t Energy: 3.11 \t Cycle: 512 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer5 \t Energy: 33.65 \t Cycle: 4608 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer6 \t Energy: 64.79 \t Cycle: 9216 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer7 \t Energy: 3.92 \t Cycle: 512 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer8 \t Energy: 13.80 \t Cycle: 2304 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer9 \t Energy: 13.01 \t Cycle: 2304 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer10 \t Energy: 2.51 \t Cycle: 256 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer11 \t Energy: 17.34 \t Cycle: 1152 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer12 \t Energy: 34.58 \t Cycle: 2304 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer13 \t Energy: 1.86 \t Cycle: 128 \t Number of same architecture layers: 1\n",
      "Name: /home/workspace/lab1/4_training_network/workloads/network-Feb-28-2023/network-Feb-28-2023_layer14 \t Energy: 0.20 \t Cycle: 8 \t Number of same architecture layers: 1\n",
      "\n",
      "Total Energy: 0.32204000 mj\n",
      "Total Cycles: 0.04634400 Million\n",
      "MACs: 10004352\n",
      "Num of Parameters: 382362\n",
      "Peak Activation Size: 98304.0 Byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "/usr/local/lib/python3.8/dist-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::hardtanh\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n",
      "OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n"
     ]
    }
   ],
   "source": [
    "from profiler import Profiler\n",
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "sub_dir = \"network-\" + today.strftime(\"%b-%d-%Y\")\n",
    "\n",
    "profiler = Profiler(\n",
    "    top_dir='workloads',\n",
    "    sub_dir=sub_dir,\n",
    "    timeloop_dir='simple_weight_stationary',\n",
    "    model=model,\n",
    "    input_size=(3, 32, 32),\n",
    "    batch_size=1,\n",
    "    convert_fc=True,\n",
    "    exception_module_names=[],\n",
    "    profiled_lib_dir=f\"profiled_lib.json\"\n",
    ")\n",
    "\n",
    "layer_wise_info, overall = profiler.profile()\n",
    "\n",
    "for layer_id, info in layer_wise_info.items():\n",
    "    print(\"Name: {} \\t Energy: {:.2f} \\t Cycle: {} \\t Number of same architecture layers: {}\".format(\n",
    "        info['name'], info['energy'], info['cycle'], info['num']))\n",
    "\n",
    "print()\n",
    "print(\"Total Energy: {:.8f} mj\".format(overall['total_energy'] / 1e3))\n",
    "print(\"Total Cycles: {:.8f} Million\".format(overall['total_cycle'] / 1e6))\n",
    "print(\"MACs: {}\".format(overall['macs']))\n",
    "print(\"Num of Parameters: {}\".format(overall['num_params']))\n",
    "print(\"Peak Activation Size: {} Byte\".format(overall['activation_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-cassette",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
